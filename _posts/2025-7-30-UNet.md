---
layout: post
title: U-Net
---

# U-Net: Convolutional Networks for Biomedical Image Segmentation 
[link to arxiv](https://arxiv.org/pdf/1505.04597)
## Summary
Built upon FCN, U-Net can segmentate input images with desired labeling wihout needing external localization. Another strength of U-Net is that it can work well with very small dataset.
## Motivation
In biomedical image processing, there are 2 field-specific problems:
	1. the desired output should include localization, i.e., a class label is supposed to be assigned to each pixel
	2. lack of training images in biomedical image processing field
## Previous works
Ciresan proposed sliding-window solution that predict the class label of each pixel by providing a local region (patch) around that pixel as input. It solves part of the issues:
	1. ability to localize;
	2. training data in patches are much larger in number than the original number of training images.
But it has 2 drawbacks:
	1. slow as the net must be run separately for each patch, and lots of redundancy due to overlapping patches
	2. trade-off between localization accuracy and the use of context. Larger patches require more max-pooling layers that reduce the localization accuracy, but small ones allow the net to see only little context.
## Structure
Built upon FCN, U-Net is modified and extended to:
	1. work with **very few** training images
	2. yield more **precise** segmentations
U-Net has a "contracting path" (now more referred to as the Decoder), and an "expansive path" (Encoder).
#### Decoder
- a "contracting path" downsamples the features to extract high level features
- 4 downsampling using max pool 2x2, each doubling # of channels, halving size
- each block has 2 consecutive 3x3 convolution layers, reducing picture size by 2 on each axis
#### Encoder
- a "expansive path" combines the upsampled the high level features and (cropped) high resolution features from previous layers to localize. 
- 4 up-sampling using up-conv 2x2 (????? transposed convolution)
- also 2 conv layers like in Decode
- first layer following up-sampling is combined with corresponding previous layer (cropped and appended)
- Last layer is obtained by applying 1x1 conv, reducing to 2 channels (foreground and background)
#### Overlap-tile strategy
- a strategy for seamless segmentation of arbitrarily large images. For border region, missing context is extrapolated by mirroring
- worth noting that, in the original paper, U-Net does not use padding in convolution layers to improve precision in segmenting continuous feature maps; however, in modern implementations, padding of 1 followed by a BN layer (before relu) is often seen to ensure that feature map shapes are preserved.
- in modern adaptations, for a high resolution image, we often split it into many subsections with overlapping edges and process each smaller pieces.
#### Data Augmentation
- again, lack of training data
- use excessive data augmentation by applying elastic deformations
	- increase training dataset size
	- learn invariance to such deformations --> important in biomedical segmentation as deformation is common in tissue
#### Separating touching objects
- Use weighted loss: separating background labels between touching cells get large weight in loss function --> help learn

## Training 
SGD with high momentum (0.99), s.t. a large number of previously seen training samples determine the update in the current optimization step

**Energy function:** pixel-wise soft-max over the final feature map combined with the cross entropy loss function

**Soft-max:** 
$$p_{k}(x)=\frac{\exp(a_{k}(x))}{\sum_{k'=1}^{K}(\exp(a_{k'}(x)))}$$
	where $a_{k}(x)$ denotes the activation in feature channel $k$ at the pixel position $x \in \Omega$ with $\Omega \subset Z^2$, $K$ is the number of classes. 
	
**Cross Entropy:** 
$$
E=\sum_{x \in \Omega}w(x)\log(p_{l(x)}(x))
$$
**Pre-computed weight map:**
$$
w(x)=w_{c}(x)+w_{0} \cdot \exp\left( -\frac{(d_{1}(x)+d_{2}(x))^2}{2 \sigma^2} \right)
$$
To avoid gradient explosion or vanishing, initial weights are chosen s.t. each feature map in the network has approx unit variance by drawing from Gaussian distribution with a standard deviation of $\sqrt{ {2}/{N} }$, where $N$ is the # of incoming nodes of one neuron.


## Results
- On the EM segmentation challenge, U-Net performs the best as described by warping error.
	- why(?):
		- maybe because in the expansive path, the up-sampled features are combined with low-level features from the contracting path, which helped U-Net to localize the labels, and in the end is able to output labels in correct topology.

